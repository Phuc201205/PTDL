import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
import emoji
import matplotlib.pyplot as plt
import seaborn as sns
from pyvi import ViTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.ensemble import BaggingClassifier
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from wordcloud import WordCloud

# =============================================================================
# 1. C·∫§U H√åNH GIAO DI·ªÜN & T·ª™ ƒêI·ªÇN
# =============================================================================
st.set_page_config(
    page_title="ABSA Sentiment Analyzer",
    page_icon="üì±",
    layout="wide"
)

# CSS t√πy ch·ªânh giao di·ªán
st.markdown("""
<style>
    .stTextArea textarea {font-size: 16px;}
    .metric-card {
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 10px;
        text-align: center;
        font-weight: bold;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        border: 1px solid #e0e0e0;
        color: #333;
    }
    
    /* ƒê·ªãnh nghƒ©a m√†u s·∫Øc cho t·ª´ng tr·∫°ng th√°i */
    .positive {background-color: #28a745; color: white; border: none;}
    .negative {background-color: #dc3545; color: white; border: none;}
    .neutral {background-color: #6c757d; color: white; border: none;}
    
    /* Style cho nh√£n kh√¥ng r√µ r√†ng (M·ªõi) */
    .not-mentioned {
        background-color: #f8f9fa; 
        color: #6c757d; 
        border: 1px dashed #ccc;
        opacity: 0.8;
    }
    
    .overall-card {
        padding: 20px;
        border-radius: 15px;
        margin-bottom: 25px;
        text-align: center;
        color: white;
        font-size: 24px;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# --- C·∫§U H√åNH T·ª™ ƒêI·ªÇN ---
ASPECTS = ['BATTERY', 'CAMERA', 'DESIGN', 'FEATURES', 'GENERAL', 'PERFORMANCE', 'PRICE', 'SCREEN', 'SER&ACC', 'STORAGE']

# [C·∫¨P NH·∫¨T] Map hi·ªÉn th·ªã bao g·ªìm c·∫£ nh√£n 0
SENTIMENT_MAP = {
    0: '‚ö™ Kh√¥ng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p r√µ r√†ng',
    1: 'üî¥ Ti√™u c·ª±c', 
    2: 'üîò Trung t√≠nh', 
    3: 'üü¢ T√≠ch c·ª±c'
} 
SENTIMENT_MAP_TRAIN = {'Negative': 1, 'Neutral': 2, 'Positive': 3}

STATIC_TEENCODE = {
    "mk": "m√¨nh", "mik": "m√¨nh", "mjk": "m√¨nh", "m": "m√¨nh", "t": "t√¥i", "tui": "t√¥i", "tao": "t√¥i", "b": "b·∫°n", "bn": "b·∫°n",
    "ad": "admin", "shop": "c·ª≠a h√†ng", "nv": "nh√¢n vi√™n", "ship": "giao h√†ng",
    "k": "kh√¥ng", "ko": "kh√¥ng", "kh": "kh√¥ng", "hok": "kh√¥ng", "not": "kh√¥ng", "ch·∫£": "ch·∫≥ng",
    "yes": "c√≥", "ye": "c√≥", "uk": "·ª´", "uhm": "·ª´", "r": "r·ªìi",
    "sp": "s·∫£n ph·∫©m", "dt": "ƒëi·ªán tho·∫°i", "ƒët": "ƒëi·ªán tho·∫°i", "d·∫ø": "ƒëi·ªán tho·∫°i", "mb": "m√°y", "mobile": "ƒëi·ªán tho·∫°i",
    "ip": "iphone", "ss": "samsung", "sam": "samsung",
    "cam": "camera", "mic": "micro", "loa": "loa", "pin": "pin", "sac": "s·∫°c",
    "dc": "ƒë∆∞·ª£c", "ƒëc": "ƒë∆∞·ª£c", "ok": "t·ªët", "okie": "t·ªët", "oke": "t·ªët", "·ªïn": "t·ªët",
    "ch√™": "kh√¥ng th√≠ch", "khen": "th√≠ch", "good": "t·ªët", "bad": "t·ªá", "nice": "t·ªët",
    "thik": "th√≠ch", "iu": "y√™u", "love": "y√™u",
    "bth": "b√¨nh th∆∞·ªùng", "bt": "b√¨nh th∆∞·ªùng",
    "lag": "gi·∫≠t", "ƒë∆°": "ƒë·ª©ng m√°y", "m∆∞·ª£t": "nhanh",
    "nh√¨u": "nhi·ªÅu", "wa": "qu√°", "w√°": "qu√°", "qa": "qu√°", "mua": "mua", "ban": "b√°n",
    "wf": "wifi", "4g": "m·∫°ng", "net": "m·∫°ng", "app": "·ª©ng d·ª•ng", "game": "tr√≤ ch∆°i",
    "fb": "facebook", "zalo": "zalo", "mess": "tin nh·∫Øn", "ib": "nh·∫Øn tin",
    "bh": "b√¢y gi·ªù", "h": "gi·ªù", "bit": "bi·∫øt", "vs": "v·ªõi", "tr": "tri·ªáu", "k": "ngh√¨n"
}

STOPWORDS = set(["b·ªã", "b·ªüi", "c·∫£", "c√°c", "c√°i", "c·∫ßn", "c√†ng", "th√¨", "l√†", "m√†"])

ASPECT_KEYWORDS = {
    'BATTERY': ['pin', 'bin', 's·∫°c', 'x·∫°c', 'mah'],
    'CAMERA': ['cam', '·∫£nh', 'ch·ª•p', 'selfie', 'quay', 'video', 'focus', 'n√©t'],
    'DESIGN': ['thi·∫øt k·∫ø', 'ƒë·∫πp', 'x·∫•u', 'm·ªèng', 'nh·∫π', 'c·∫ßm', 'n·∫Øm', 'l∆∞ng', 'vi·ªÅn', 'nh·ª±a', 'nh√¥m', 'k√≠nh', 'ngo·∫°i h√¨nh'],
    'FEATURES': ['wifi', '4g', '5g', 's√≥ng', 'v√¢n tay', 'face id', 'loa', '√¢m', 'sim', 'esim', 'bluetooth', 'k·∫øt n·ªëi'],
    'PERFORMANCE': ['game', 'li√™n qu√¢n', 'pubg', 'l√°c', 'lag', 'gi·∫≠t', 'm∆∞·ª£t', 'nhanh', 'ch·∫≠m', 'treo', 'ƒë∆°', 'n√≥ng', 'nhi·ªát', 'chip', 'ram', 't√°c v·ª•', 'hi·ªáu nƒÉng'],
    'PRICE': ['gi√°', 'ti·ªÅn', 'ƒë·∫Øt', 'r·∫ª', 'h·ª£p l√Ω', 'm·∫Øc', 'chi ph√≠', 'v√≠'],
    'SCREEN': ['m√†n', 'h√¨nh', 'hi·ªÉn th·ªã', 'n√©t', 'r·ªó', '√°m', 't·ªëi', 's√°ng', 't·∫ßn s·ªë qu√©t', 'hz', 'oled', 'lcd'],
    'SER&ACC': ['giao', 'ship', 'ƒë√≥ng g√≥i', 'h·ªôp', 'nh√¢n vi√™n', 'shop', 't∆∞ v·∫•n', 'b·∫£o h√†nh', 'ph·ª• ki·ªán', 'tai nghe', 'c√°p', 'c·ªß s·∫°c'],
    'STORAGE': ['gb', 'tb', 'b·ªô nh·ªõ', 'l∆∞u', 'tr·ªØ', 'dung l∆∞·ª£ng'],
    'GENERAL': []
}

SENTIMENT_KEYWORDS = [
    't·ªët', 'x·∫•u', 'khen', 'ch√™', 'ngon', 'd·ªü', 't·ªá', 'k√©m', '·ªïn', 'ok', 'ƒë∆∞·ª£c', 'th√≠ch', 'y√™u', 'gh√©t',
    'm∆∞·ª£t', 'lag', 'gi·∫≠t', 'ƒë∆°', 'nhanh', 'ch·∫≠m', 'n√≥ng', 'm√°t', '·∫•m', 'tr√¢u', 'y·∫øu', 'b·ªÅn', 'l·ªüm',
    'n√©t', 'm·ªù', 'r√µ', 'nh√≤e', 'r·ªó', 's·∫Øc', '·∫£o', 'ƒë·∫πp', 'x·∫•u', 'sang', 'th√¥', 'm·ªèng', 'd√†y', 'n·∫∑ng', 'nh·∫π',
    'r·∫ª', 'ƒë·∫Øt', 'h·ª£p l√Ω', 'm·∫Øc', 'ch√°t', 'cao', 'th·∫•p',
    'to', 'nh·ªè', 'b√©', 'l·ªõn', 'r√®', 'v·ªçng', '√™m',
    'nh·∫°y', 'ngu', 'th√¥ng minh', 'l·ªói', 'x·ªãn', 'd·ªèm', 'fake', 'h∆∞', 'h·ªèng',
    'nhi·ªát t√¨nh', 'th√¢n thi·ªán', 'l√°o', 'c·ªçc', 'nhanh', 'l√¢u', 'ch·∫≠m', 'c·∫©n th·∫≠n', 'm√≥p', 'r√°ch',
    'th·∫•t v·ªçng', 'h√†i l√≤ng', '∆∞ng', 'ph√™', 'ch√°n', 'ti·∫øc', 'ph√≠', 'ƒë√°ng', 'tuy·ªát'
]

# =============================================================================
# 2. H√ÄM X·ª¨ L√ù TEXT
# =============================================================================
def clean_text_ultimate(text):
    if pd.isna(text): return ""
    text = str(text).lower()

    text = re.sub(r'\b\d+\s?(gb|tb|g|mb)\b', ' token_memory ', text)
    text = re.sub(r'b·ªô nh·ªõ\s?(trong)?', ' token_memory ', text)
    text = re.sub(r'l∆∞u tr·ªØ', ' token_memory ', text)
    text = re.sub(r'th·∫ª nh·ªõ', ' token_memory ', text)
    text = re.sub(r'ƒë·∫ßy\s?b·ªô\s?nh·ªõ', ' token_memory_full ', text)

    text = re.sub(r'\b\d+\s?hz\b', ' token_hz ', text)
    text = re.sub(r't·∫ßn s·ªë qu√©t', ' token_hz ', text)

    text = emoji.demojize(text, delimiters=(" ", " "))
    text = unicodedata.normalize('NFC', text)

    sorted_keys = sorted(STATIC_TEENCODE.keys(), key=len, reverse=True)
    pattern = re.compile(r'\b(' + '|'.join(map(re.escape, sorted_keys)) + r')\b')
    text = pattern.sub(lambda x: STATIC_TEENCODE[x.group()], text)

    text = re.sub(r'[^\w\s]', ' ', text)
    text = ViTokenizer.tokenize(text)

    tokens = [t for t in text.split() if t not in STOPWORDS]
    return " ".join(tokens)

# =============================================================================
# 3. H√ÄM HU·∫§N LUY·ªÜN MODEL
# =============================================================================
@st.cache_resource
def train_model(uploaded_file):
    df = pd.read_csv(uploaded_file)
    
    if 'BATTERY' not in df.columns:
        def parse_labels(row):
            res = {asp: 0 for asp in ASPECTS}
            if pd.isna(row['label']): return pd.Series(res)
            tags = row['label'].split(';')
            for tag in tags:
                tag = tag.strip().replace('{', '').replace('}', '')
                if '#' in tag:
                    parts = tag.split('#')
                    asp, sent = parts[0], parts[1] if len(parts) > 1 else None
                    if asp in ASPECTS and sent in SENTIMENT_MAP_TRAIN: 
                        res[asp] = SENTIMENT_MAP_TRAIN[sent]
            return pd.Series(res)
        label_df = df.apply(parse_labels, axis=1)
        df = pd.concat([df, label_df], axis=1)

    df['comment_cleaned'] = df['comment'].apply(clean_text_ultimate)
    df_clean = df.dropna(subset=['comment_cleaned'])
    df_clean = df_clean[df_clean['comment_cleaned'].str.strip().astype(bool)]

    vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1, 3), min_df=2, sublinear_tf=True)
    X_vec_all = vectorizer.fit_transform(df_clean['comment_cleaned'].values)
    models = {}

    progress_bar = st.progress(0)
    
    for idx, aspect in enumerate(ASPECTS):
        y = df_clean[aspect].values
        mask = (y != 0)
        
        X_curr = X_vec_all[mask]
        y_curr = y[mask] - 1 

        if len(y_curr) < 10:
            base_svc = LinearSVC(class_weight='balanced', random_state=42)
            if len(y_curr) > 0:
                base_svc.fit(X_curr, y_curr)
                models[aspect] = base_svc
            else:
                models[aspect] = None
            continue

        X_train, _, y_train, _ = train_test_split(X_curr, y_curr, test_size=0.1, random_state=42, stratify=y_curr)

        try:
            rus = RandomUnderSampler(random_state=42)
            X_train_res, y_train_res = rus.fit_resample(X_train, y_train)
        except:
            X_train_res, y_train_res = X_train, y_train
            
        try:
            min_samples = sorted(dict(pd.Series(y_train_res).value_counts()).values())[0]
            k = min(3, min_samples - 1)
            if k > 0:
                smote = SMOTE(k_neighbors=k, random_state=42)
                X_train_res, y_train_res = smote.fit_resample(X_train_res, y_train_res)
        except:
            pass

        base_svc = LinearSVC(class_weight='balanced', random_state=42, dual=False, max_iter=3000)
        model = BaggingClassifier(estimator=base_svc, n_estimators=10, random_state=42, n_jobs=-1)
        
        model.fit(X_train_res, y_train_res)
        models[aspect] = model
        
        progress_bar.progress((idx + 1) / len(ASPECTS))
    
    progress_bar.empty()
    return vectorizer, models, df_clean

# =============================================================================
# 4. HARD RULES & HYBRID LOGIC
# =============================================================================
def has_aspect_keyword(text, aspect):
    if aspect == 'GENERAL': return True
    keywords = ASPECT_KEYWORDS.get(aspect, [])
    return any(kw in text for kw in keywords)

def has_sentiment_keyword(text):
    return any(kw in text for kw in SENTIMENT_KEYWORDS)

def check_strict_sentiment(raw_text, aspect):
    if aspect == 'GENERAL': return True
    segments = re.split(r'[.,;!]+', raw_text)
    for seg in segments:
        seg_clean = clean_text_ultimate(seg).lower().replace('_', ' ')
        if has_aspect_keyword(seg_clean, aspect):
            if has_sentiment_keyword(seg_clean):
                return True
    return False

def apply_hard_rules_hybrid(text, pred_vector):
    text_lower = text.lower()
    
    def set_force(asp_name, val):
        idx = ASPECTS.index(asp_name)
        pred_vector[idx] = val

    def has_kw(keywords):
        return any(kw in text_lower for kw in keywords)

    neg_dep = ['kh√¥ng ƒë·∫πp', 'ko ƒë·∫πp', 'k ƒë·∫πp', 'ch·∫£ ƒë·∫πp', 'ch·∫≥ng ƒë·∫πp', 'x·∫•u', 'th√¥']
    neg_net = ['kh√¥ng n√©t', 'ko n√©t', 'k n√©t', 'm·ªù', 'kh√¥ng r√µ', 'k r√µ']
    pos_design_strong = ['m√°y ƒë·∫πp', 'ƒët ƒë·∫πp', 'ƒëi·ªán tho·∫°i ƒë·∫πp', 'thi·∫øt k·∫ø ƒë·∫πp', 'ngo·∫°i h√¨nh ƒë·∫πp', 'nh√¨n ƒë·∫πp']

    contrast_words = ['tuy nhi√™n', 'nh∆∞ng m√†', 'c√≥ ƒëi·ªÅu', 'm·ªói t·ªôi', 'ƒëi·ªÉm tr·ª´', 'ti·∫øc l√†']
    for word in contrast_words:
        if word in text_lower:
            parts = text_lower.split(word)
            if len(parts) > 1:
                after_part = parts[1]
                if 'cam' in after_part and not has_kw(['n√©t', 'ƒë·∫πp']): set_force('CAMERA', 1)
                if 'pin' in after_part: set_force('BATTERY', 1)
                if 'm√†n' in after_part: set_force('SCREEN', 1)
                if 'n√≥ng' in after_part: set_force('PERFORMANCE', 1)

    if has_kw(['thi·∫øt k·∫ø', 'ngo·∫°i h√¨nh', 'ki·ªÉu d√°ng', 'm√°y', 'ƒëi·ªán tho·∫°i']):
        if has_kw(pos_design_strong): set_force('DESIGN', 3)
        elif has_kw(neg_dep) or has_kw(['nh·ª±a', '·ªçp ·∫πp', 'l·ªèng l·∫ªo', 'c·∫•n']): set_force('DESIGN', 1)
        elif has_kw(['ƒë·∫πp', 'sang', 'x·ªãn', 'm·ªèng', 'nh·∫π', 'c·∫ßm s∆∞·ªõng']): set_force('DESIGN', 3)

    if has_kw(['pin', 'bin']):
        if has_kw(['tr√¢u', 'kh·ªèe', 'l√¢u', 'c·∫£ ng√†y', 'ngon']): set_force('BATTERY', 3)
        if has_kw(['tu·ªôt', 't·ª•t', 'y·∫øu', 'h·∫ªo', 'nhanh h·∫øt', 's·ª•t', 'k√©m']): set_force('BATTERY', 1)
        if has_kw(['trung b√¨nh', 'ƒë·ªß d√πng', 'bth', 'b√¨nh th∆∞·ªùng']): set_force('BATTERY', 2)

    if has_kw(['m√†n h√¨nh', 'm√†n']):
        if has_kw(neg_dep) or has_kw(neg_net) or has_kw(['r·ªó', '√°m', 't·ªëi', 'ƒë∆°', 'lo·∫°n', 's·ªçc']): set_force('SCREEN', 1)
        elif has_kw(['n√©t', 'ƒë·∫πp', 's·∫Øc', 'm∆∞·ª£t', 't∆∞∆°i']): set_force('SCREEN', 3)

    if has_kw(['cam', '·∫£nh', 'ch·ª•p', 'selfie', 'quay']):
        if has_kw(neg_dep) or has_kw(neg_net) or has_kw(['m·ªù', 'b·ªÉ', 'nh√≤e', 't·ªá', 'k√©m', 'rung', 'b·ªát']): set_force('CAMERA', 1)
        elif has_kw(['n√©t', 'ƒë·∫πp', '·∫£o', 'ngon', 'r√µ', 'xu·∫•t s·∫Øc', 'chi ti·∫øt']): set_force('CAMERA', 3)

    if has_kw(['n√≥ng', '·∫•m m√°y', 't·ªèa nhi·ªát', 'lo·∫°n c·∫£m ·ª©ng']): set_force('PERFORMANCE', 1)
    if has_kw(['lag', 'gi·∫≠t', 'treo logo', 'kh·ª±ng', 'ƒë·ª©ng h√¨nh']): set_force('PERFORMANCE', 1)
    if has_kw(['game', 'li√™n qu√¢n', 'pubg', 't√°c v·ª•', 'hi·ªáu nƒÉng']):
        if has_kw(['k ngon', 'kh√¥ng ngon', 'ch√°n']): set_force('PERFORMANCE', 1)
        elif has_kw(['m∆∞·ª£t', 'ph√™', 'nhanh', 'chi·∫øn', 'ngon']): set_force('PERFORMANCE', 3)
        elif has_kw(['b√¨nh th∆∞·ªùng', '·ªïn', 't·∫°m']): set_force('PERFORMANCE', 2)

    idx_price = ASPECTS.index('PRICE')
    if pred_vector[idx_price] == 3:
        if not has_kw(['r·∫ª', 't·ªët', 'h·ª£p l√Ω', 'ok', 'ngon', 'gi·∫£m', 'sale', 'ƒë√°ng', 'm·ªÅm']):
            pred_vector[idx_price] = 0
    if has_kw(['gi√°', 'ti·ªÅn']):
        if has_kw(['r·∫ª', 't·ªët', 'h·ª£p l√Ω', 'm·ªÅm']): set_force('PRICE', 3)
        if has_kw(['ƒë·∫Øt', 'cao', 'ch√°t', 'm·∫Øc']): set_force('PRICE', 1)

    if has_kw(['nh√¢n vi√™n', 't∆∞ v·∫•n', 'shop', 'ph·ª•c v·ª•']):
        if has_kw(['nhi·ªát t√¨nh', 't·ªët', 'd·ªÖ th∆∞∆°ng', 'th√¢n thi·ªán']): set_force('SER&ACC', 3)
        if has_kw(['th√°i ƒë·ªô', 't·ªá', 'l√°o', 'c·ªçc']): set_force('SER&ACC', 1)

    if has_kw(['th·∫•t v·ªçng', 'ƒë·ª´ng mua', 'ph√≠ ti·ªÅn']): set_force('GENERAL', 1)
    if has_kw(['nh√¨n chung', 't·ªïng th·ªÉ']):
        if has_kw(['ƒë·∫πp', 't·ªët', 'ok']): set_force('GENERAL', 3)

    return pred_vector

# =============================================================================
# 5. GIAO DI·ªÜN STREAMLIT CH√çNH
# =============================================================================
st.sidebar.title("‚öôÔ∏è B·∫£ng ƒëi·ªÅu khi·ªÉn")
uploaded_file = st.sidebar.file_uploader("Upload file Training (CSV)", type=['csv'])

if uploaded_file is not None:
    st.sidebar.success("File ƒë√£ t·∫£i l√™n!")
    if st.sidebar.button("Hu·∫•n luy·ªán M√¥ h√¨nh üöÄ"):
        with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh Bagging SVC + SMOTE..."):
            try:
                vectorizer, models, df_visual = train_model(uploaded_file)
                st.session_state['vectorizer'] = vectorizer
                st.session_state['models'] = models
                st.session_state['df_visual'] = df_visual
                st.sidebar.success("Hu·∫•n luy·ªán ho√†n t·∫•t!")
            except Exception as e:
                st.sidebar.error(f"C√≥ l·ªói x·∫£y ra: {e}")
else:
    st.sidebar.info("Vui l√≤ng t·∫£i file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

st.title("üì± H·ªá Th·ªëng Ph√¢n T√≠ch C·∫£m X√∫c ƒêi·ªán Tho·∫°i")

tab1, tab2 = st.tabs(["üîç Ph√¢n T√≠ch B√¨nh Lu·∫≠n", "üìä Tr·ª±c Quan H√≥a D·ªØ Li·ªáu"])

# --- TAB 1: PH√ÇN T√çCH ---
with tab1:
    col1, col2 = st.columns([2, 1])

    with col1:
        user_input = st.text_area("Nh·∫≠p b√¨nh lu·∫≠n c·ªßa kh√°ch h√†ng:", height=150, placeholder="V√≠ d·ª•: M√°y d√πng t·ªët, pin tr√¢u nh∆∞ng camera h∆°i m·ªù...")
        analyze_btn = st.button("Ph√¢n t√≠ch ngay ‚ú®", type="primary")

    if analyze_btn and user_input:
        if 'models' not in st.session_state:
            st.error("‚ö†Ô∏è Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc!")
        else:
            cleaned_text = clean_text_ultimate(user_input)
            vec_input = st.session_state['vectorizer'].transform([cleaned_text])
            
            text_lower_cleaned = cleaned_text.lower().replace('_', ' ')
            text_raw_lower = user_input.lower()
            
            mentioned_aspects = [asp for asp in ASPECTS if asp != 'GENERAL' and has_aspect_keyword(text_lower_cleaned, asp)]
            is_multi_aspect = len(mentioned_aspects) > 1

            ml_preds_vector = []
            for aspect in ASPECTS:
                if st.session_state['models'][aspect] is None:
                    pred_label = 0
                else:
                    pred_label = st.session_state['models'][aspect].predict(vec_input)[0] + 1
                
                if pred_label != 0:
                    if not has_aspect_keyword(text_lower_cleaned, aspect):
                        pred_label = 0
                    elif aspect != 'GENERAL':
                        if is_multi_aspect:
                            if not check_strict_sentiment(text_raw_lower, aspect):
                                pred_label = 0
                        else:
                            if not has_sentiment_keyword(text_lower_cleaned):
                                pred_label = 0
                ml_preds_vector.append(pred_label)
            
            final_preds = apply_hard_rules_hybrid(user_input, np.array(ml_preds_vector))
            
            active_sentiments = [p for p in final_preds if p != 0]
            
            st.markdown("---")
            
            # T√≠nh to√°n t·ªïng quan
            if not active_sentiments:
                st.warning("H·ªá th·ªëng ch∆∞a t√¨m th·∫•y kh√≠a c·∫°nh n√†o r√µ r√†ng ƒë·ªÉ k·∫øt lu·∫≠n t·ªïng quan.")
            else:
                n_pos = active_sentiments.count(3)
                n_neg = active_sentiments.count(1)
                
                if n_pos > n_neg:
                    overall_html = f"""<div class="overall-card positive">üåü K·∫æT LU·∫¨N: KH√ÅCH H√ÄNG H√ÄI L√íNG</div>"""
                elif n_neg > n_pos:
                    overall_html = f"""<div class="overall-card negative">üò° K·∫æT LU·∫¨N: KH√ÅCH H√ÄNG KH√îNG H√ÄI L√íNG</div>"""
                else:
                    overall_html = f"""<div class="overall-card neutral">‚öñÔ∏è K·∫æT LU·∫¨N: ƒê√ÅNH GI√Å TRUNG T√çNH / TR√ÅI CHI·ªÄU</div>"""
                
                st.markdown(overall_html, unsafe_allow_html=True)

            # [C·∫¨P NH·∫¨T GIAO DI·ªÜN] Hi·ªÉn th·ªã t·∫•t c·∫£ nh√£n, bao g·ªìm c·∫£ nh√£n 0
            st.subheader("üìù Chi ti·∫øt ph√¢n t√≠ch:")
            cols = st.columns(4)
            col_idx = 0
            
            for i, aspect in enumerate(ASPECTS):
                sentiment = final_preds[i]
                
                # Class CSS t∆∞∆°ng ·ª©ng
                if sentiment == 3: color_class = "positive"
                elif sentiment == 1: color_class = "negative"
                elif sentiment == 2: color_class = "neutral"
                else: color_class = "not-mentioned" # Class m·ªõi cho nh√£n 0
                
                label_text = SENTIMENT_MAP[sentiment]
                
                with cols[col_idx % 4]:
                    st.markdown(f"""
                    <div class="metric-card {color_class}">
                        <div>{aspect}</div>
                        <div style="font-size: 1.1em; font-weight: normal;">{label_text}</div>
                    </div>
                    """, unsafe_allow_html=True)
                col_idx += 1

    with col2:
        st.markdown("### ‚ÑπÔ∏è H∆∞·ªõng d·∫´n")
        st.info("""
        **Quy tr√¨nh:**
        1. T·∫£i file CSV hu·∫•n luy·ªán.
        2. Nh·∫•n n√∫t "Hu·∫•n luy·ªán".
        3. Nh·∫≠p b√¨nh lu·∫≠n v√† xem k·∫øt qu·∫£.
        
        **Ch√∫ th√≠ch:**
        - üü¢ Xanh: T√≠ch c·ª±c
        - üî¥ ƒê·ªè: Ti√™u c·ª±c
        - üîò X√°m ƒê·∫≠m: Trung t√≠nh
        - ‚ö™ X√°m Nh·∫°t: Kh√¥ng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p
        """)
        if 'models' in st.session_state:
            st.success("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")

# --- TAB 2: TR·ª∞C QUAN H√ìA ---
with tab2:
    if 'df_visual' not in st.session_state:
        st.warning("‚ö†Ô∏è Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh ·ªü Tab 'Ph√¢n T√≠ch' ƒë·ªÉ t·∫£i d·ªØ li·ªáu!")
    else:
        df = st.session_state['df_visual']
        st.header("üìä Dashboard Ph√¢n T√≠ch D·ªØ Li·ªáu")
        
        # 1. Ph√¢n ph·ªëi Sao
        st.subheader("1. Ph√¢n ph·ªëi ƒë√°nh gi√° sao (1-5)")
        fig1, ax1 = plt.subplots(figsize=(8, 4))
        if 'n_star' in df.columns:
            sns.countplot(x=df["n_star"], color="#33CCFF", ax=ax1)
            st.pyplot(fig1)
        else:
            st.write("Kh√¥ng t√¨m th·∫•y c·ªôt 'n_star'.")

        # 2. T·ªïng quan Sentiment
        st.subheader("2. T·ª∑ l·ªá C·∫£m x√∫c To√†n h·ªá th·ªëng")
        polarity_counts = {
            "Negative": (df[ASPECTS] == 1).sum().sum(),
            "Neutral":  (df[ASPECTS] == 2).sum().sum(),
            "Positive": (df[ASPECTS] == 3).sum().sum(),
        }
        fig2, ax2 = plt.subplots()
        ax2.pie(polarity_counts.values(), labels=polarity_counts.keys(), autopct='%1.1f%%', colors=['#dc3545', '#6c757d', '#28a745'])
        st.pyplot(fig2)

        # 3. Bar Chart
        st.subheader("3. Chi ti·∫øt C·∫£m x√∫c theo Kh√≠a c·∫°nh")
        aspect_sentiment = pd.DataFrame({
            "Aspect": ASPECTS,
            "Negative": [(df[a] == 1).sum() for a in ASPECTS],
            "Neutral":  [(df[a] == 2).sum() for a in ASPECTS],
            "Positive": [(df[a] == 3).sum() for a in ASPECTS],
        })
        fig3 = aspect_sentiment.set_index("Aspect").plot(kind="bar", figsize=(12, 6), color=['#dc3545', '#6c757d', '#28a745']).figure
        st.pyplot(fig3)

        # 4. Heatmap
        st.subheader("4. Ma tr·∫≠n T∆∞∆°ng quan gi·ªØa c√°c Kh√≠a c·∫°nh")
        corr = df[ASPECTS].replace({0: np.nan}).corr()
        fig4, ax4 = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr, annot=True, cmap="coolwarm", ax=ax4)
        st.pyplot(fig4)

        # 5. WordCloud (ƒê√É S·ª¨A L·ªñI CRASH)
        st.subheader("5. T·ª´ kh√≥a n·ªïi b·∫≠t (WordCloud)")
        col_wc1, col_wc2 = st.columns(2)
        
        positive_text = " ".join(df[df[ASPECTS].eq(3).any(axis=1)]["comment_cleaned"])
        negative_text = " ".join(df[df[ASPECTS].eq(1).any(axis=1)]["comment_cleaned"])
        
        with col_wc1:
            st.write("**T·ª´ kh√≥a T√≠ch c·ª±c**")
            # [FIX L·ªñI] Ki·ªÉm tra ƒë·ªô d√†i text ƒë·ªÉ tr√°nh crash
            if len(positive_text.strip()) > 0:
                try:
                    wc_pos = WordCloud(width=400, height=300, background_color="white").generate(positive_text)
                    fig_p, ax_p = plt.subplots()
                    ax_p.imshow(wc_pos, interpolation='bilinear')
                    ax_p.axis("off")
                    st.pyplot(fig_p)
                except ValueError:
                    st.info("D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ t·∫°o WordCloud.")
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu t√≠ch c·ª±c.")
        
        with col_wc2:
            st.write("**T·ª´ kh√≥a Ti√™u c·ª±c**")
            if len(negative_text.strip()) > 0:
                try:
                    wc_neg = WordCloud(width=400, height=300, background_color="white", colormap="Reds").generate(negative_text)
                    fig_n, ax_n = plt.subplots()
                    ax_n.imshow(wc_neg, interpolation='bilinear')
                    ax_n.axis("off")
                    st.pyplot(fig_n)
                except ValueError:
                    st.info("D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ t·∫°o WordCloud.")
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ti√™u c·ª±c.")
